# ğŸ§  Fort Wise Voice AI Assistant

A powerful **Voice-to-Voice Assistant powered by Whisper, FAISS, GPT-4o, and TTS** that takes voice input, retrieves knowledge via FAISS, answers using **GPT-4o**, and responds back with natural **TTS (Text-to-Speech)** audio.  
Built with **FastAPI** for the backend and **Streamlit** for a simple web UI.

---

## ğŸŒŸ Features

- ğŸ¹ Voice Input (WAV/MP3) using **Whisper** STT
- ğŸ” Semantic Search using **FAISS**
- ğŸ§  Response Generation with **GPT-4o**
- ğŸ‘¤ Voice Output via **OpenAI TTS**
- ğŸ§  Context Memory for follow-up conversations
- ğŸŒ Streamlit-based Web UI
- ğŸš€ FastAPI-powered REST API
- âœ… Unit-tested for reliability
- ğŸ³ Dockerized for easy deployment

---

## ğŸ³ Quickstart with Docker (Recommended)

Build and run the app with Docker Compose:

```bash
docker-compose up --build
```

Access the backend API:  
â¡ï¸ `http://localhost:8000`

Access the Streamlit UI:  
â¡ï¸ `http://localhost:8501`

> **Note**: Make sure you configure your `.env` file correctly before building the Docker image!

If you make changes to the code, rebuild the containers:

```bash
docker-compose down
docker-compose up --build
```

---

## ğŸ“ Folder Structure

```
Voice-AI-Assistant/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â””â”€â”€ services/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ knowledge_base.txt
â”‚   â””â”€â”€ faiss_index/
â”œâ”€â”€ telegram_bot/
â”‚   â””â”€â”€ bot.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_*.py
â”‚   â””â”€â”€ audio/
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.py
â””â”€â”€ run.sh
```

---

## ğŸ§ª Manual Setup Instructions (Local Development)

### 1. Clone the repository

```bash
git clone https://github.com/VaibhavMishra173/Voice-AI-Assistant.git
cd Voice-AI-Assistant
```

### 2. Create and activate virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
# OR
venv\Scripts\activate  # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
pip install git+https://github.com/openai/whisper.git
```

### 4. Configure Environment Variables

Create a `.env` file based on `.env.example`:

```
# API Keys
OPENAI_API_KEY=your_openai_api_key_here

# Google Cloud TTS (optional for future)
GOOGLE_CLOUD_CREDENTIALS_JSON=path/to/your/credentials.json

# App Config
MAX_AUDIO_DURATION=30
USE_OPENAI_TTS=True
USE_OPENAI_STT=True

# Path Configs
DATA_PATH=data/knowledge_base.txt
FAISS_INDEX_PATH=data/faiss_index/index.faiss

# Models
MODEL_NAME=gpt-4o
WHISPER_MODEL=base
TTS_VOICE=alloy  # Options: echo, fable, onyx, nova, shimmer
CONTEXT_MEMORY_TURNS=15

# URLs
API_BASE_URL=http://localhost:8000
# IMPORTANT: For Docker, use service name instead of localhost
# API_BASE_URL=http://voice-ai-fastapi:8000
```

---

## ğŸš€ Running the Application Locally

### 1. Start Backend API (FastAPI)

```bash
uvicorn api.main:app --reload
```

Access the backend at:  
â¡ï¸ `http://127.0.0.1:8000`

---

### 2. Start Web UI (Streamlit)

```bash
streamlit run ui/streamlit_app.py
```

Access the UI at:  
â¡ï¸ `http://localhost:8501`

In the UI you can:
- Upload or record voice input
- View the transcription
- See relevant document retrieval
- Hear the AI's voice reply

---

## ğŸ’ª Running Tests

Run all unit tests:

```bash
pytest tests/
```

---

## ğŸ“¡ API Example Usage

Send an audio file to the backend:

```bash
curl -X POST http://127.0.0.1:8000/chat/ask \
  -F "audio=@sample_audio.wav" \
  -H "accept: application/json"
```

---

## ğŸ¤– Telegram Bot (Optional, In Progress)

- Listens for voice messages.
- Sends them to your backend `/chat/ask` API.
- Replies with generated audio responses.

Run the bot:

```bash
python telegram_bot/bot.py
```

---

## ğŸ“„ Notes & Improvements

- Multi-turn conversation with context memory.
- Full error handling and centralized logging.
- Easily configurable via `.env`.
- Backend ready for production deployment.
- **Planned Features:**
  - Production deployment (Render / Railway / GCP)
  - Better long-context memory
  - Multilingual support
  - Real-time streaming conversations

---

## â¤ï¸ Credits

- [OpenAI](https://openai.com/) â€” Whisper, GPT-4o, TTS APIs
- [FAISS](https://github.com/facebookresearch/faiss) â€” Nearest Neighbor Search
- [Streamlit](https://streamlit.io/) â€” Web UI Framework
- [FastAPI](https://fastapi.tiangolo.com/) â€” API Framework

---

## ğŸ“¬ Contact

For any issues, questions, or contributions:  
ğŸ“§ vaibhavmishra173@gmail.com  
ğŸ”— [GitHub Profile](https://github.com/VaibhavMishra173)

---

# ğŸš€ Let's build the future of voice-first AI assistants!

